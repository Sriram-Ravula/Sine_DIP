{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import math\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(nn.Module):\n",
    "    def __init__(self, nz, ngf=64, output_size=1024, nc=1, num_measurements=64):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Deconv Layers: (in_channels, out_channels, kernel_size, stride, padding, bias = false)\n",
    "        # Inputs: R^(N x Cin x Lin), Outputs: R^(N, Cout, Lout) s.t. Lout = (Lin - 1)*stride - 2*padding + kernel_size\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose1d(nz, ngf, 4, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 1: input: (random) zϵR^(nzx1), output: x1ϵR^(64x4) (channels x length)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 2: input: x1ϵR^(64x4), output: x2ϵR^(64x8) (channels x length)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 3: input: x1ϵR^(64x8), output: x2ϵR^(64x16) (channels x length)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 4: input: x1ϵR^(64x16), output: x2ϵR^(64x32) (channels x length)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 5: input: x2ϵR^(64x32), output: x3ϵR^(64x64) (channels x length)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn6 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 6: input: x3ϵR^(64x64), output: x4ϵR^(64x128) (channels x length)\n",
    "\n",
    "        self.conv7 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn7 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 7: input: x4ϵR^(64x128), output: x5ϵR^(64x256) (channels x length)\n",
    "\n",
    "        self.conv8 = nn.ConvTranspose1d(ngf, ngf, 6, 2, 2, bias=False)\n",
    "        self.bn8 = nn.BatchNorm1d(ngf)\n",
    "        # LAYER 8: input: x5ϵR^(64x256), output: x6ϵR^(64x512) (channels x length)\n",
    "\n",
    "        self.conv9 = nn.ConvTranspose1d(ngf, nc, 4, 2, 1, bias=False)  # output is image\n",
    "        # LAYER 9: input: x6ϵR^(64x512), output: (sinusoid) G(z,w)ϵR^(1x1024) (channels x length)\n",
    "\n",
    "        self.fc = nn.Linear(output_size * nc, num_measurements, bias=False)  # output is A; measurement matrix\n",
    "        # each entry should be drawn from a Gaussian (random noisy measurements)\n",
    "        # don't compute gradient of self.fc! memory issues\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = F.relu(self.bn7(self.conv7(x)))\n",
    "        x = F.relu(self.bn8(self.conv8(x)))\n",
    "        x = F.tanh(self.conv9(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def measurements(self, x):\n",
    "        # this gives the image - make it a single row vector of appropriate length\n",
    "        y = self.forward(x).view(1, -1)\n",
    "        y = y.cpu()\n",
    "\n",
    "        # pass thru FC layer - returns A*image\n",
    "        meas = self.fc(y)\n",
    "\n",
    "        if CUDA:\n",
    "            return meas.cuda()\n",
    "        else:\n",
    "            return meas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
